from sentence_transformers import SentenceTransformer
from transformers import pipeline
import faiss
import numpy as np

# ============================
# 1. D·ªÆ LI·ªÜU C√îNG TY
# ============================

company_knowledge = [
    "C√¥ng ty ABC ƒë∆∞·ª£c th√†nh l·∫≠p v√†o ng√†y 12 th√°ng 3 nƒÉm 2015.",
    "C√¥ng ty c√≥ ba ph√≤ng ban ch√≠nh: Ph√≤ng Nh√¢n s·ª±, Ph√≤ng K·ªπ thu·∫≠t, v√† Ph√≤ng Kinh doanh.",
    "Gi√°m ƒë·ªëc ƒëi·ªÅu h√†nh hi·ªán t·∫°i l√† √¥ng Nguy·ªÖn VƒÉn A.",
    "Ph√≤ng Nh√¢n s·ª± ch·ªãu tr√°ch nhi·ªám tuy·ªÉn d·ª•ng v√† ph√∫c l·ª£i cho nh√¢n vi√™n.",
    "Ph√≤ng K·ªπ thu·∫≠t ph·ª• tr√°ch ph√°t tri·ªÉn ph·∫ßn m·ªÅm v√† h·∫° t·∫ßng c√¥ng ngh·ªá.",
    "Ph√≤ng Kinh doanh x·ª≠ l√Ω kh√°ch h√†ng v√† h·ª£p ƒë·ªìng d·ªãch v·ª•.",
    "Tr·ª• s·ªü ch√≠nh c·ªßa c√¥ng ty n·∫±m t·∫°i 123 ƒë∆∞·ªùng ABC, Qu·∫≠n 1, TP. H·ªì Ch√≠ Minh.",
    "C√¥ng ty c√≥ h∆°n 200 nh√¢n vi√™n t√≠nh ƒë·∫øn nƒÉm 2024.",
    "S·ª© m·ªánh c·ªßa c√¥ng ty l√† mang l·∫°i gi·∫£i ph√°p c√¥ng ngh·ªá t·ªëi ∆∞u cho doanh nghi·ªáp Vi·ªát."
]

# ============================
# 2. T·∫†O EMBEDDING + FAISS
# ============================

print("ƒêang kh·ªüi t·∫°o m√¥ h√¨nh embedding...")
embedder = SentenceTransformer('all-MiniLM-L6-v2')
doc_embeddings = embedder.encode(company_knowledge, convert_to_numpy=True)

print("ƒêang t·∫°o FAISS index...")
index = faiss.IndexFlatL2(doc_embeddings.shape[1])
index.add(doc_embeddings)

# ============================
# 3. T·∫¢I M√î H√åNH TR·∫¢ L·ªúI
# ============================

print("ƒêang t·∫£i m√¥ h√¨nh tr·∫£ l·ªùi c√¢u h·ªèi...")
qa_model = pipeline(
    "text2text-generation",
    model="VietAI/vit5-base",  # C√≥ th·ªÉ thay ƒë·ªïi n·∫øu b·∫°n d√πng local
    device_map="auto", 
    model_kwargs={"torch_dtype": "auto"},
    max_new_tokens=200,
    temperature=0.2
)

# ============================
# 4. H√ÄM TR·∫¢ L·ªúI C√ÇU H·ªéI
# ============================

def answer_question(question, top_k=3):
    # B∆∞·ªõc 1: Encode c√¢u h·ªèi
    q_embedding = embedder.encode([question], convert_to_numpy=True)

    # B∆∞·ªõc 2: T√¨m c√°c c√¢u n·ªôi dung li√™n quan nh·∫•t
    D, I = index.search(q_embedding, k=top_k)
    related_docs = [company_knowledge[i] for i in I[0]]

    # B∆∞·ªõc 3: T·∫°o prompt
    context = "\n".join(related_docs)
    prompt = f"""D∆∞·ªõi ƒë√¢y l√† th√¥ng tin n·ªôi b·ªô c√¥ng ty:

{context}

D·ª±a tr√™n th√¥ng tin tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi sau:
C√¢u h·ªèi: {question}
Tr·∫£ l·ªùi:"""

    # B∆∞·ªõc 4: Tr·∫£ l·ªùi
    result = qa_model(prompt)[0]['generated_text']
    
    # C·∫Øt ph·∫ßn tr·∫£ l·ªùi n·∫øu m√¥ h√¨nh l·∫∑p l·∫°i prompt
    return result.split("Tr·∫£ l·ªùi:")[-1].strip()

# ============================
# 5. Giao di·ªán ƒë∆°n gi·∫£n
# ============================

if __name__ == "__main__":
    print("\n=== H·ªÜ TH·ªêNG H·ªéI ƒê√ÅP V·ªÄ C√îNG TY ===")
    while True:
        query = input("\nNh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n (ho·∫∑c 'exit' ƒë·ªÉ tho√°t): ")
        if query.lower().strip() == "exit":
            print("T·∫°m bi·ªát!")
            break
        answer = answer_question(query)
        print(f"\nüìå Tr·∫£ l·ªùi: {answer}")
